{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLNRxIk9q098AewhbEiEtw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "HANDS-ON SESSION-II\n",
        "\n",
        "Maahi Subedi\n",
        "\n",
        "Ait 664-DL3\n",
        "\n",
        "REGRESSION MODELS"
      ],
      "metadata": {
        "id": "rgP_mGm38mu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "import numpy as np\n",
        ""
      ],
      "metadata": {
        "id": "oN7EGNB88wFN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housingprice=pd.read_csv('/content/ny_housing.csv')\n",
        "housingprice.dropna(inplace=True)\n",
        "target = 'PRICE'\n",
        ""
      ],
      "metadata": {
        "id": "xqEo7a8i8y1F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categorical and numerical columns\n",
        "categorical_cols = ['TYPE']\n",
        "numerical_cols = ['PRICE', 'BEDS', 'BATH',\t'PROPERTYSQFT']\n",
        "\n",
        "# One-hot encode categorical features\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "encoded_data = encoder.fit_transform(housingprice[categorical_cols])\n",
        "\n",
        "# Create a DataFrame from encoded data\n",
        "encoded_columns = encoder.get_feature_names_out(categorical_cols)\n",
        "df_encoded = pd.DataFrame(encoded_data, columns=encoded_columns, index=housingprice.index)\n",
        "\n",
        "# Combine numerical data and encoded categorical data\n",
        "X = pd.concat([housingprice[numerical_cols], df_encoded], axis=1)\n",
        "y = housingprice[target]\n",
        "\n",
        "# Scale the features for better performance of regression models\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "iJXgtxS99Fk9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into 70% training and 30% test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "cNTUAkhZ9n1W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Linear Regression model\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Linear Regression model\n",
        "print(\"Linear Regression Mean Squared Error:\", mean_squared_error(y_test, y_pred_linear))\n",
        "print(\"Linear Regression R^2 Score:\", r2_score(y_test, y_pred_linear))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnQ0v_8t9xxM",
        "outputId": "d0186a10-4070-4cab-dea0-7e823626406b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Mean Squared Error: 1.0107911815883683e-13\n",
            "Linear Regression R^2 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest Regressor\n",
        "print(\"Random Forest Regressor Mean Squared Error:\", mean_squared_error(y_test, y_pred_rf))\n",
        "print(\"Random Forest Regressor R^2 Score:\", r2_score(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvR1IC3j92Vl",
        "outputId": "0831e00a-eb90-4c13-9e09-d93e9dfd5afe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Mean Squared Error: 280915666440.554\n",
            "Random Forest Regressor R^2 Score: 0.9857835269930872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a RandomForestRegressor with regularization parameters\n",
        "regressor = RandomForestRegressor(\n",
        "    n_estimators=100,          # Number of trees\n",
        "    max_depth=10,              # Limit the depth of each tree\n",
        "    min_samples_split=5,       # Minimum samples required to split an internal node\n",
        "    min_samples_leaf=4,        # Minimum samples required to be at a leaf node\n",
        "    max_features='sqrt',       # Use the square root of the total features at each split\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Random Forest Regressor Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"Random Forest Regressor R^2 Score:\", r2_score(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AycVK5AI95Mt",
        "outputId": "11e88f1a-ffb3-4847-a1f9-080263fda288"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Mean Squared Error: 58727360328370.586\n",
            "Random Forest Regressor R^2 Score: 0.9857835269930872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X and y are your features and target variable\n",
        "# Define the model with regularization parameters\n",
        "regressor = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=5,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=4,\n",
        "    max_features='sqrt',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Set up k-fold cross-validation (5 folds)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation and calculate MSE for each fold\n",
        "scores = cross_val_score(\n",
        "    regressor, X, y, cv=kf, scoring=make_scorer(mean_squared_error)\n",
        ")\n",
        "\n",
        "# Calculate the mean and standard deviation of the MSE scores\n",
        "mean_mse = np.mean(scores)\n",
        "std_mse = np.std(scores)\n",
        "\n",
        "print(f\"Mean MSE from cross-validation: {mean_mse:.2f}\")\n",
        "print(f\"R^2 Score: {r2_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH655Dqq99yE",
        "outputId": "5c51a1fa-c8ae-4811-cecf-37a1120f77fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MSE from cross-validation: 972835892033484.25\n",
            "R^2 Score: -1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the gradient boosting model with different parameters\n",
        "gbm_model = GradientBoostingRegressor(n_estimators=300, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred_gbm = gbm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Gradient Boosting Regressor\n",
        "print(\"Gradient Boosting Regressor Mean Squared Error:\", mean_squared_error(y_test, y_pred_gbm))\n",
        "print(\"Gradient Boosting Regressor R^2 Score:\", r2_score(y_test, y_pred_gbm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjAle2LW-DCU",
        "outputId": "54e02f70-7d6e-4421-bb6f-cdf3c7e6113a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor Mean Squared Error: 92259062914.92688\n",
            "Gradient Boosting Regressor R^2 Score: 0.9953309884984621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# L2 Regularization: Ridge Regression\n",
        "ridge = Ridge(alpha=1.0)  # alpha controls the regularization strength; higher means more regularization\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge_predictions = ridge.predict(X_test)\n",
        "print(\"Ridge MSE:\", mean_squared_error(y_test, ridge_predictions))\n",
        "print(\"Ridge R^2 Score:\", r2_score(y_test, ridge_predictions))\n",
        "\n",
        "# L1 Regularization: Lasso Regression\n",
        "lasso = Lasso(alpha=0.1)  # alpha is the regularization parameter\n",
        "lasso.fit(X_train, y_train)\n",
        "lasso_predictions = lasso.predict(X_test)\n",
        "print(\"Lasso MSE:\", mean_squared_error(y_test, lasso_predictions))\n",
        "print(\"Lasso R^2 Score:\", r2_score(y_test, lasso_predictions))\n",
        "\n",
        "# L1 + L2 Regularization: Elastic Net\n",
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # l1_ratio balances between L1 and L2 (0 = pure L2, 1 = pure L1)\n",
        "elastic_net.fit(X_train, y_train)\n",
        "elastic_net_predictions = elastic_net.predict(X_test)\n",
        "print(\"Elastic Net MSE:\", mean_squared_error(y_test, elastic_net_predictions))\n",
        "print(\"Elastic Net R^2 Score:\", r2_score(y_test, elastic_net_predictions))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiaErlvm-GYO",
        "outputId": "9e9845a0-add0-4ee5-cdbc-d134733d6950"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge MSE: 1534052.183138152\n",
            "Ridge R^2 Score: 0.9999999223652717\n",
            "Lasso MSE: 0.00010241741407229526\n",
            "Lasso R^2 Score: 1.0\n",
            "Elastic Net MSE: 36223361872.125725\n",
            "Elastic Net R^2 Score: 0.9981668219049518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion: **\n",
        "\n",
        "Linear Regression: 1.0\n",
        "\n",
        "Random Forest Regressor: 0.99\n",
        "\n",
        "Random Forest Regressor w/ regularization: 0.99\n",
        "\n",
        "Gradient Boosting Regressor: 0.99\n",
        "\n",
        "Ridge: 0.99\n",
        "\n",
        "Lasso: 1.0\n",
        "\n",
        "Elastic: 0.99\n",
        "\n",
        "In Regression model, Linear regression and Lasso regression are the best model among others."
      ],
      "metadata": {
        "id": "LbuZLZDc-KuU"
      }
    }
  ]
}